{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np \n",
    "import pandas as pd \n",
    "from sklearn.model_selection import train_test_split\n",
    "import seaborn as sns\n",
    "from matplotlib import pyplot as plt\n",
    "import math\n",
    "\n",
    "from matplotlib.font_manager import FontProperties\n",
    "\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "import lightgbm as lgb\n",
    "import xgboost as xgb\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.metrics import mean_absolute_percentage_error\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset\n",
    "training_data_file = '/Users/jellyfish/Desktop/玉山/dataset_1st/training.csv'\n",
    "testing_data_file = '/Users/jellyfish/Desktop/玉山/dataset_1st/public_processed.csv'\n",
    "testing_submit = '/Users/jellyfish/Desktop/玉山/31_範例繳交檔案.csv'\n",
    "submit_file = '/Users/jellyfish/Desktop/玉山/submission/submission.csv'\n",
    "private_file = '/Users/jellyfish/Desktop/玉山/dataset_2nd/private_1_processed.csv'\n",
    "\n",
    "\n",
    "# Read data\n",
    "train_df = pd.read_csv(training_data_file)\n",
    "test_df = pd.read_csv(testing_data_file)\n",
    "private_df = pd.read_csv(private_file)\n",
    "test_sb = pd.read_csv(testing_submit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>txkey</th>\n",
       "      <th>pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>a2c1209018e4e52e04f6fabb48f05f1b8bc09dc838ff6c...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>16c4880500059e01553789be11bbb50753b7acaae7b95b...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>623c56be3bee87724e3d119c271d9ed098eeda84233183...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>250da12187059cf6e3a3066656a2919d08ceb8207efd55...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4b268e0da036f44cbbb056ddfac6a28ea336d9cf299843...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               txkey  pred\n",
       "0  a2c1209018e4e52e04f6fabb48f05f1b8bc09dc838ff6c...     0\n",
       "1  16c4880500059e01553789be11bbb50753b7acaae7b95b...     0\n",
       "2  623c56be3bee87724e3d119c271d9ed098eeda84233183...     0\n",
       "3  250da12187059cf6e3a3066656a2919d08ceb8207efd55...     0\n",
       "4  4b268e0da036f44cbbb056ddfac6a28ea336d9cf299843...     0"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_sb.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "private_df 和 test_df 中相同的 'txkey' 數量為：754139\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# 假設 private_df 和 test_df 是兩個 DataFrame\n",
    "# 使用 merge 函數合併兩個 DataFrame，找出相同的 'txkey'\n",
    "merged_df = pd.merge(private_df, test_sb, on='txkey')\n",
    "\n",
    "# 取得合併後的 DataFrame 中相同 'txkey' 的數量\n",
    "num_common_txkey = merged_df['txkey'].nunique()\n",
    "\n",
    "print(f\"private_df 和 test_df 中相同的 'txkey' 數量為：{num_common_txkey}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "private_df 和 test_df 中相同的 'txkey' 數量為：600182\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# 假設 private_df 和 test_df 是兩個 DataFrame\n",
    "# 使用 merge 函數合併兩個 DataFrame，找出相同的 'txkey'\n",
    "merged_df = pd.merge(test_df, test_sb, on='txkey')\n",
    "\n",
    "# 取得合併後的 DataFrame 中相同 'txkey' 的數量\n",
    "num_common_txkey = merged_df['txkey'].nunique()\n",
    "\n",
    "print(f\"private_df 和 test_df 中相同的 'txkey' 數量為：{num_common_txkey}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1354321, 2)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_sb.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "test2_df = pd.read_csv(testing_data_file)\n",
    "test2_sb = pd.read_csv(testing_submit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_column_titles = [\n",
    "    \"交易序號\", \"授權日期\", \"授權時間\", \"顧客ID\", \"交易卡號\", \"交易類別\", \"交易型態\",\n",
    "    \"特店代號\", \"收單行代碼\", \"mcc_code\", \"交易金額-台幣\", \"網路交易註記\", \"是否分期交易\",\n",
    "    \"分期期數\", \"是否紅利交易\", \"實付金額\", \"消費地國別\", \"消費城市\", \"狀態碼\", \"超額註記碼\",\n",
    "    \"Fallback註記\", \"支付型態\", \"消費地幣別\", \"消費地金額\", \"3D交易註記\", \"盜刷與否\"\n",
    "]\n",
    "\n",
    "train_df = train_df.rename(columns=dict(zip(train_df.columns, new_column_titles)))\n",
    "test_df = test_df.rename(columns=dict(zip(test_df.columns, new_column_titles)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "交易序號                0\n",
       "授權日期                0\n",
       "授權時間                0\n",
       "顧客ID                0\n",
       "交易卡號                0\n",
       "交易類別                0\n",
       "交易型態           203455\n",
       "特店代號                0\n",
       "收單行代碼               0\n",
       "mcc_code         4550\n",
       "交易金額-台幣             0\n",
       "網路交易註記              0\n",
       "是否分期交易              0\n",
       "分期期數                0\n",
       "是否紅利交易              0\n",
       "實付金額                0\n",
       "消費地國別             600\n",
       "消費城市           266066\n",
       "狀態碼           8665195\n",
       "超額註記碼               0\n",
       "Fallback註記          0\n",
       "支付型態           286656\n",
       "消費地幣別          498657\n",
       "消費地金額               0\n",
       "3D交易註記              0\n",
       "盜刷與否                0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# null process\n",
    "train_df['交易型態'].fillna(train_df['交易型態'].mode()[0], inplace=True)\n",
    "train_df['mcc_code'].fillna(train_df['mcc_code'].mode()[0], inplace=True)\n",
    "train_df['消費地國別'].fillna(train_df['消費地國別'].mode()[0], inplace=True)\n",
    "train_df['支付型態'].fillna(train_df['支付型態'].mode()[0], inplace=True)\n",
    "\n",
    "train_df.dropna(subset=['消費城市'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df['消費地幣別'] = np.where(train_df['消費地幣別'] == 70, 1, 0)\n",
    "test_df['消費地幣別'] = np.where(test_df['消費地幣別'] == 70, 1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df['卡片交易次數'] = train_df.groupby('交易卡號')['交易卡號'].transform('count')\n",
    "test_df['卡片交易次數'] = test_df.groupby('交易卡號')['交易卡號'].transform('count')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df['特店交易次數'] = train_df.groupby('特店代號')['特店代號'].transform('count')\n",
    "test_df['特店交易次數'] = test_df.groupby('特店代號')['特店代號'].transform('count')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df['顧客交易次數'] = train_df.groupby('顧客ID')['顧客ID'].transform('count')\n",
    "test_df['顧客交易次數'] = test_df.groupby('顧客ID')['顧客ID'].transform('count')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# label encoding\n",
    "combined_df = pd.concat([train_df, test_df])\n",
    "\n",
    "label_encoder = LabelEncoder()\n",
    "combined_df['收單行代碼'] = label_encoder.fit_transform(combined_df['收單行代碼'])\n",
    "\n",
    "# Split\n",
    "train_df['收單行代碼'] = combined_df['收單行代碼'][:len(train_df)]\n",
    "test_df['收單行代碼'] = combined_df['收單行代碼'][len(train_df):]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 處理授權時間\n",
    "def convert_to_hms(seconds):\n",
    "    hours = seconds // 10000\n",
    "    minutes = (seconds % 10000) // 100\n",
    "    seconds = seconds % 100\n",
    "    return hours, minutes, seconds\n",
    "\n",
    "train_df['授權時間-小時'] = train_df['授權時間'].apply(lambda x: convert_to_hms(x)[0])\n",
    "test_df['授權時間-小時'] = test_df['授權時間'].apply(lambda x: convert_to_hms(x)[0])\n",
    "\n",
    "train_df.drop(columns=['授權時間'],inplace=True)\n",
    "test_df.drop(columns=['授權時間'],inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'授權日期'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[0;32m~/anaconda3/envs/test/lib/python3.11/site-packages/pandas/core/indexes/base.py:3652\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3651\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m-> 3652\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_engine\u001b[39m.\u001b[39;49mget_loc(casted_key)\n\u001b[1;32m   3653\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mKeyError\u001b[39;00m \u001b[39mas\u001b[39;00m err:\n",
      "File \u001b[0;32m~/anaconda3/envs/test/lib/python3.11/site-packages/pandas/_libs/index.pyx:147\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/anaconda3/envs/test/lib/python3.11/site-packages/pandas/_libs/index.pyx:176\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:7080\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:7088\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: '授權日期'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[32], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m train_df[\u001b[39m'\u001b[39m\u001b[39m卡片一日交易次數\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m train_df\u001b[39m.\u001b[39mgroupby([\u001b[39m'\u001b[39m\u001b[39m交易卡號\u001b[39m\u001b[39m'\u001b[39m, train_df[\u001b[39m'\u001b[39;49m\u001b[39m授權日期\u001b[39;49m\u001b[39m'\u001b[39;49m]])[\u001b[39m'\u001b[39m\u001b[39m授權日期\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m.\u001b[39mtransform(\u001b[39m'\u001b[39m\u001b[39mcount\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m      2\u001b[0m test_df[\u001b[39m'\u001b[39m\u001b[39m卡片一日交易次數\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m test_df\u001b[39m.\u001b[39mgroupby([\u001b[39m'\u001b[39m\u001b[39m交易卡號\u001b[39m\u001b[39m'\u001b[39m, test_df[\u001b[39m'\u001b[39m\u001b[39m授權日期\u001b[39m\u001b[39m'\u001b[39m]])[\u001b[39m'\u001b[39m\u001b[39m授權日期\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m.\u001b[39mtransform(\u001b[39m'\u001b[39m\u001b[39mcount\u001b[39m\u001b[39m'\u001b[39m)\n",
      "File \u001b[0;32m~/anaconda3/envs/test/lib/python3.11/site-packages/pandas/core/frame.py:3760\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3758\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcolumns\u001b[39m.\u001b[39mnlevels \u001b[39m>\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[1;32m   3759\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_getitem_multilevel(key)\n\u001b[0;32m-> 3760\u001b[0m indexer \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcolumns\u001b[39m.\u001b[39;49mget_loc(key)\n\u001b[1;32m   3761\u001b[0m \u001b[39mif\u001b[39;00m is_integer(indexer):\n\u001b[1;32m   3762\u001b[0m     indexer \u001b[39m=\u001b[39m [indexer]\n",
      "File \u001b[0;32m~/anaconda3/envs/test/lib/python3.11/site-packages/pandas/core/indexes/base.py:3654\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3652\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_engine\u001b[39m.\u001b[39mget_loc(casted_key)\n\u001b[1;32m   3653\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mKeyError\u001b[39;00m \u001b[39mas\u001b[39;00m err:\n\u001b[0;32m-> 3654\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mKeyError\u001b[39;00m(key) \u001b[39mfrom\u001b[39;00m \u001b[39merr\u001b[39;00m\n\u001b[1;32m   3655\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mTypeError\u001b[39;00m:\n\u001b[1;32m   3656\u001b[0m     \u001b[39m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[1;32m   3657\u001b[0m     \u001b[39m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[1;32m   3658\u001b[0m     \u001b[39m#  the TypeError.\u001b[39;00m\n\u001b[1;32m   3659\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[0;31mKeyError\u001b[0m: '授權日期'"
     ]
    }
   ],
   "source": [
    "train_df['卡片一日交易次數'] = train_df.groupby(['交易卡號', train_df['授權日期']])['授權日期'].transform('count')\n",
    "test_df['卡片一日交易次數'] = test_df.groupby(['交易卡號', test_df['授權日期']])['授權日期'].transform('count')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df['卡片一日交易次數'] = train_df.groupby(['交易卡號', train_df['mcc_code']])['mcc_code'].transform('count')\n",
    "test_df['卡片一日交易次數'] = test_df.groupby(['交易卡號', test_df['mcc_code']])['mcc_code'].transform('count')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 捨棄的features\n",
    "train_df.drop(columns=['交易序號'],inplace=True)\n",
    "train_df.drop(columns=['消費城市'],inplace=True)\n",
    "train_df.drop(columns=['狀態碼'],inplace=True)\n",
    "train_df.drop(columns=['交易卡號'],inplace=True)\n",
    "train_df.drop(columns=['顧客ID'],inplace=True)\n",
    "train_df.drop(columns=['特店代號'],inplace=True)\n",
    "train_df.drop(columns=['授權日期'],inplace=True)\n",
    "\n",
    "test_df.drop(columns=['交易序號'],inplace=True)\n",
    "test_df.drop(columns=['消費城市'],inplace=True)\n",
    "test_df.drop(columns=['狀態碼'],inplace=True)\n",
    "test_df.drop(columns=['交易卡號'],inplace=True)\n",
    "test_df.drop(columns=['顧客ID'],inplace=True)\n",
    "test_df.drop(columns=['特店代號'],inplace=True)\n",
    "test_df.drop(columns=['授權日期'],inplace=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = train_df.iloc[:,train_df.columns != '盜刷與否']\n",
    "Y = train_df['盜刷與否']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_valid, y_train, y_valid = train_test_split(X, Y, train_size=0.8, test_size=0.2, random_state=42, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\tvalid-logloss:0.66869\n",
      "[1]\tvalid-logloss:0.64542\n",
      "[2]\tvalid-logloss:0.62327\n",
      "[3]\tvalid-logloss:0.60218\n",
      "[4]\tvalid-logloss:0.58201\n",
      "[5]\tvalid-logloss:0.56274\n",
      "[6]\tvalid-logloss:0.54432\n",
      "[7]\tvalid-logloss:0.52672\n",
      "[8]\tvalid-logloss:0.50983\n",
      "[9]\tvalid-logloss:0.49366\n",
      "[10]\tvalid-logloss:0.47816\n",
      "[11]\tvalid-logloss:0.46324\n",
      "[12]\tvalid-logloss:0.44895\n",
      "[13]\tvalid-logloss:0.43518\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[31], line 24\u001b[0m\n\u001b[1;32m     19\u001b[0m     model \u001b[39m=\u001b[39m xgb\u001b[39m.\u001b[39mtrain(params\u001b[39m=\u001b[39mparams,\n\u001b[1;32m     20\u001b[0m                       dtrain\u001b[39m=\u001b[39mdtrain, num_boost_round\u001b[39m=\u001b[39m\u001b[39m10000\u001b[39m,\n\u001b[1;32m     21\u001b[0m                       early_stopping_rounds\u001b[39m=\u001b[39m\u001b[39m500\u001b[39m, evals\u001b[39m=\u001b[39m[(dvalid, \u001b[39m'\u001b[39m\u001b[39mvalid\u001b[39m\u001b[39m'\u001b[39m)])\n\u001b[1;32m     22\u001b[0m     \u001b[39mreturn\u001b[39;00m model\n\u001b[0;32m---> 24\u001b[0m xgbmodel \u001b[39m=\u001b[39m XGBmodel(X_train, X_valid, y_train, y_valid, params)\n",
      "Cell \u001b[0;32mIn[31], line 19\u001b[0m, in \u001b[0;36mXGBmodel\u001b[0;34m(X_train, X_valid, y_train, y_valid, params)\u001b[0m\n\u001b[1;32m     17\u001b[0m dtrain \u001b[39m=\u001b[39m xgb\u001b[39m.\u001b[39mDMatrix(X_train, label\u001b[39m=\u001b[39my_train)\n\u001b[1;32m     18\u001b[0m dvalid \u001b[39m=\u001b[39m xgb\u001b[39m.\u001b[39mDMatrix(X_valid, label\u001b[39m=\u001b[39my_valid)\n\u001b[0;32m---> 19\u001b[0m model \u001b[39m=\u001b[39m xgb\u001b[39m.\u001b[39;49mtrain(params\u001b[39m=\u001b[39;49mparams,\n\u001b[1;32m     20\u001b[0m                   dtrain\u001b[39m=\u001b[39;49mdtrain, num_boost_round\u001b[39m=\u001b[39;49m\u001b[39m10000\u001b[39;49m,\n\u001b[1;32m     21\u001b[0m                   early_stopping_rounds\u001b[39m=\u001b[39;49m\u001b[39m500\u001b[39;49m, evals\u001b[39m=\u001b[39;49m[(dvalid, \u001b[39m'\u001b[39;49m\u001b[39mvalid\u001b[39;49m\u001b[39m'\u001b[39;49m)])\n\u001b[1;32m     22\u001b[0m \u001b[39mreturn\u001b[39;00m model\n",
      "File \u001b[0;32m~/anaconda3/envs/test/lib/python3.11/site-packages/xgboost/core.py:620\u001b[0m, in \u001b[0;36mrequire_keyword_args.<locals>.throw_if.<locals>.inner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    618\u001b[0m \u001b[39mfor\u001b[39;00m k, arg \u001b[39min\u001b[39;00m \u001b[39mzip\u001b[39m(sig\u001b[39m.\u001b[39mparameters, args):\n\u001b[1;32m    619\u001b[0m     kwargs[k] \u001b[39m=\u001b[39m arg\n\u001b[0;32m--> 620\u001b[0m \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/anaconda3/envs/test/lib/python3.11/site-packages/xgboost/training.py:185\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(params, dtrain, num_boost_round, evals, obj, feval, maximize, early_stopping_rounds, evals_result, verbose_eval, xgb_model, callbacks, custom_metric)\u001b[0m\n\u001b[1;32m    183\u001b[0m \u001b[39mif\u001b[39;00m cb_container\u001b[39m.\u001b[39mbefore_iteration(bst, i, dtrain, evals):\n\u001b[1;32m    184\u001b[0m     \u001b[39mbreak\u001b[39;00m\n\u001b[0;32m--> 185\u001b[0m bst\u001b[39m.\u001b[39;49mupdate(dtrain, i, obj)\n\u001b[1;32m    186\u001b[0m \u001b[39mif\u001b[39;00m cb_container\u001b[39m.\u001b[39mafter_iteration(bst, i, dtrain, evals):\n\u001b[1;32m    187\u001b[0m     \u001b[39mbreak\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/test/lib/python3.11/site-packages/xgboost/core.py:1918\u001b[0m, in \u001b[0;36mBooster.update\u001b[0;34m(self, dtrain, iteration, fobj)\u001b[0m\n\u001b[1;32m   1915\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_validate_dmatrix_features(dtrain)\n\u001b[1;32m   1917\u001b[0m \u001b[39mif\u001b[39;00m fobj \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m-> 1918\u001b[0m     _check_call(_LIB\u001b[39m.\u001b[39;49mXGBoosterUpdateOneIter(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mhandle,\n\u001b[1;32m   1919\u001b[0m                                             ctypes\u001b[39m.\u001b[39;49mc_int(iteration),\n\u001b[1;32m   1920\u001b[0m                                             dtrain\u001b[39m.\u001b[39;49mhandle))\n\u001b[1;32m   1921\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   1922\u001b[0m     pred \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpredict(dtrain, output_margin\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m, training\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# XGBoost\n",
    "params = {\n",
    "    'max_depth': 8,\n",
    "    'n_estimators': 5000,\n",
    "    'gamma': 0.003,\n",
    "    'eta': 0.025,\n",
    "    'subsample': 0.9,\n",
    "    'colsample_bytree': 0.7,\n",
    "    'objective': 'binary:logistic',  \n",
    "    'eval_metric': 'logloss',  \n",
    "    'silent': 0,\n",
    "    'verbosity': 0,\n",
    "    'random_state': 42,\n",
    "}\n",
    "\n",
    "def XGBmodel(X_train, X_valid, y_train, y_valid, params):\n",
    "    dtrain = xgb.DMatrix(X_train, label=y_train)\n",
    "    dvalid = xgb.DMatrix(X_valid, label=y_valid)\n",
    "    model = xgb.train(params=params,\n",
    "                      dtrain=dtrain, num_boost_round=10000,\n",
    "                      early_stopping_rounds=500, evals=[(dvalid, 'valid')])\n",
    "    return model\n",
    "\n",
    "xgbmodel = XGBmodel(X_train, X_valid, y_train, y_valid, params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testing data\n",
    "X_test = test_df\n",
    "w1 = 1.0\n",
    "w2 = 0.0\n",
    "\n",
    "test_pred_xgb = xgbmodel.predict(xgb.DMatrix(X_test)).tolist()\n",
    "test_pred = np.asarray(w1) * test_pred_xgb\n",
    "\n",
    "threshold = 0.5  \n",
    "y_pred_binary = [1 if pred > threshold else 0 for pred in test_pred]\n",
    "\n",
    "submission = pd.DataFrame()\n",
    "submission['txkey'] = test2_df['txkey']\n",
    "submission['pred'] = y_pred_binary\n",
    "submission.to_csv(submit_file, index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "test",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
